{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_084_HW_JWEN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRKilNRMHPej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import keras\n",
        "import itertools\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2tvur2vHZwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test=keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdL4oLzkHfFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preproc_x(x,flatten=True):\n",
        "  x=x/255.\n",
        "  if flatten:\n",
        "    x=x.reshape((len(x),-1))\n",
        "  return x\n",
        "\n",
        "def preproc_y(y,num_classes=10):\n",
        "  if y.shape[-1]==1:\n",
        "    y=keras.utils.to_categorical(y,num_classes)\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffLauaSwH3xR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train=train\n",
        "x_test,y_test=test\n",
        "\n",
        "x_train=preproc_x(x_train)\n",
        "x_test=preproc_x(x_test)\n",
        "\n",
        "y_train=preproc_y(y_train)\n",
        "y_test=preproc_y(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z92XG8ScH8ZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "def build_mlp(input_shape,output_units=10,num_neurons=[512,256,128]):\n",
        "  input_layer=keras.layers.Input(input_shape)\n",
        "\n",
        "  for i,n_units in enumerate(num_neurons):\n",
        "    if i==0:\n",
        "      x=keras.layers.Dense(units=n_units,activation='relu',name='hidden_layer'+str(i+1))(input_layer)\n",
        "      x=BatchNormalization()(x)\n",
        "    else:\n",
        "      x=keras.layers.Dense(units=n_units,activation='relu',name='hidden_layer'+str(i+1))(x)\n",
        "      x=BatchNormalization()(x)\n",
        "  out=keras.layers.Dense(units=output_units,activation='softmax',name='output')(x)\n",
        "\n",
        "  model=keras.models.Model(inputs=[input_layer],outputs=[out])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5SHtAZQI_PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
        "EPOCHS=50\n",
        "BATCH_SIZE=256\n",
        "MOMENTUM=0.95\n",
        "OPTIMIZER=[keras.optimizers.SGD,keras.optimizers.RMSprop,keras.optimizers.Adagrad,keras.optimizers.Adam]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gZJirDTpttC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results={}\n",
        "for lr,opti in itertools.product(LEARNING_RATE,OPTIMIZER):\n",
        "  keras.backend.clear_session()\n",
        "  print('Experiment with LR=%.6f, Optimizer=%s' %(lr,str(opti)))\n",
        "  model=build_mlp(input_shape=x_train.shape[1:])\n",
        "  model.summary()\n",
        "\n",
        "  optimizer=opti(lr=lr)\n",
        "  model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=optimizer)\n",
        "\n",
        "  model.fit(x_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_data=(x_test,y_test),shuffle=True)\n",
        "  train_loss = model.history.history[\"loss\"]\n",
        "  valid_loss = model.history.history[\"val_loss\"]\n",
        "  train_acc = model.history.history[\"acc\"]\n",
        "  valid_acc = model.history.history[\"val_acc\"]\n",
        "    \n",
        "  exp_name_tag = \"exp-lr-%s-optimizer-%s\" % (str(lr), str(opti))\n",
        "  results[exp_name_tag] = {'train-loss': train_loss,\n",
        "                           'valid-loss': valid_loss,\n",
        "                           'train-acc': train_acc,\n",
        "                           'valid-acc': valid_acc}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqBJ86nJuGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "NUM_COLORS=len(results.keys())\n",
        "cm=plt.get_cmap('gist_rainbow')\n",
        "color_bar=[cm(1.*i/NUM_COLORS)] for i in range(NUM_COLORS)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "for i,cond in enumerate(results.keys()):\n",
        "  plt.plot(range(len(results[cond]['train-loss'])), results[cond]['train-loss'],'-', label=cond,color=color_bar[i])\n",
        "  plt.plot(range(len(results[cond]['valid-loss'])), results[cond]['valid-loss'],'--', label=cond,color=color_bar[i])\n",
        "  \n",
        "plt.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "for i,cond in enumerate(results.keys()):\n",
        "  plt.plot(range(len(results[cond]['train-acc'])), results[cond]['train-acc'],'-', label=cond,color=color_bar[i])\n",
        "  plt.plot(range(len(results[cond]['valid-acc'])), results[cond]['valid-acc'],'--', label=cond,color=color_bar[i])\n",
        "  \n",
        "plt.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}