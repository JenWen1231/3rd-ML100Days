{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_088_HW_JWEN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEVVP5ZjpVvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYAvsfETpgOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test=keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyiGuZlEplpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StrUyxCepnix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOm0DnrDpqux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "    \n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "        if i == 0:\n",
        "            x = keras.layers.Dense(units=n_units, \n",
        "                                   activation=\"relu\", \n",
        "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
        "            x = BatchNormalization()(x)\n",
        "        else:\n",
        "            x = keras.layers.Dense(units=n_units, \n",
        "                                   activation=\"relu\", \n",
        "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
        "            x = BatchNormalization()(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOf_nnIspx6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 1024\n",
        "MOMENTUM = 0.95"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_0CwbtwpznA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "class f1sc(Callback):\n",
        "  def on_train_begin(self,epoch,logs={}):\n",
        "    logs=logs or {}\n",
        "    record_items=['val_auc','val_f1sc','val_fp','val_fn','val_tp','val_tn']\n",
        "    for i in recor_items:\n",
        "      if i not in self.params['metrics']:\n",
        "        self.params['metrics'].append(i)\n",
        "  def on_epoch_end(self,epoch,logs={},thres=0.5):\n",
        "    logs=logs or {}\n",
        "    y_true=self.validation_data[1].argmax(axis=1)\n",
        "    y_pred=self.model.predict(self.validation_data[0])\n",
        "    y_pred=(y_pred[:,1]>=thres)*1\n",
        "\n",
        "    logs['val_f1sc']=f1_score(y_true=y_true,y_pred=y_red,average='weighted')\n",
        "\n",
        "  log_f1sc=fisc()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ8RCVxksnFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_mlp(input_shape=x_train.shape[1:])\n",
        "model.summary()\n",
        "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=EPOCHS, \n",
        "          batch_size=BATCH_SIZE, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True,\n",
        "          callbacks=[log_f1sc]\n",
        "         )\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "\n",
        "#valid_f1sc = model.history.history['val_f1sc']\n",
        "valid_tp =  model.history.history['val_tp']\n",
        "valid_tn =  model.history.history['val_tn']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtKuxHYXsz1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(valid_tp)), valid_tp, label=\"valid tp\", color=\"navy\")\n",
        "plt.plot(range(len(valid_tn)), valid_tn, label=\"valid tn\", color=\"red\")\n",
        "plt.legend()\n",
        "plt.title(\"True positives and True Negatives\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}