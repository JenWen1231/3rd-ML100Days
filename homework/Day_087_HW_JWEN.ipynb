{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day_087_HW_JWEN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPPUJ7upKWewYOTjbv/vuYP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"89rDR7pqi821","colab_type":"code","colab":{}},"source":["import os\n","import keras\n","import itertools\n","\n","os.environ['CUDA_VISIBLE_DEVICES']='0'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dsbsRsm6jLWN","colab_type":"code","colab":{}},"source":["train,test=keras.datasets.cifar10.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLGvjtmxjPcQ","colab_type":"code","colab":{}},"source":["def preproc_x(x, flatten=True):\n","    x = x / 255.\n","    if flatten:\n","        x = x.reshape((len(x), -1))\n","    return x\n","\n","def preproc_y(y, num_classes=10):\n","    if y.shape[-1] == 1:\n","        y = keras.utils.to_categorical(y, num_classes)\n","    return y   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPKCtsGajR1Y","colab_type":"code","colab":{}},"source":["x_train, y_train = train\n","x_test, y_test = test\n","\n","x_train = preproc_x(x_train)\n","x_test = preproc_x(x_test)\n","\n","y_train = preproc_y(y_train)\n","y_test = preproc_y(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFYBBxKTjVfA","colab_type":"code","colab":{}},"source":["from keras.layers import BatchNormalization\n","\n","def build_mlp(input_shape,output_units=10,num_neurons=[512,256,128]):\n","  input_layer=keras.layers.Input(input_shape)\n","\n","  for i,n_units in enumerate(num_neurons):\n","    if i==0:\n","      x=keras.layers.Dense(units=n_units,activation='relu',name='hidden_layer'+str(i+1))(input_layer)\n","      x=BatchNormalization()(x)\n","    else:\n","      x=keras.layers.Dense(units=n_units,activation='relu',name='hidden_layer'+str(i+1))(x)\n","      x=BatchNormalization()(x)\n","  out=keras.layers.Dense(units=output_units,activaion='softmax',name='output')(x)\n","\n","  model=keras.models.Model(inputs=[input_layer],outputs=[out])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9HeNKE-PkVBK","colab_type":"code","colab":{}},"source":["LEARNING_RATE = 1e-3 #[1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n","EPOCHS = 50\n","BATCH_SIZE = 256\n","OPTIMIZER = [keras.optimizers.SGD, keras.optimizers.RMSprop, keras.optimizers.Adagrad, keras.optimizers.Adam]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9sd1v3akt4J","colab_type":"code","colab":{}},"source":["from keras.callbacks import ReduceROnPlateau\n","\n","ft=[0.5,0.2,0.7,0.9]\n","pe=[5,3,7,9]\n","reduce_lr=ReduceLROnPlateau(factor=ft,min_lr=1e-12,monitor='val_loss',patience=pe,verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_fnlefvkjJe","colab_type":"code","colab":{}},"source":["results = {}\n","for fct,pte, opti in itertools.product(ft,pe, OPTIMIZER):\n","    keras.backend.clear_session() \n","    print(\"Experiment with Optimizer = %s ,factor=%s , pte=%s\" % (str(opti),str(fct),str(pte)))\n","    model = build_mlp(input_shape=x_train.shape[1:])\n","    model.summary()\n","    \n","    optimizer = opti\n","    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n","\n","    model.fit(x_train, y_train, \n","              epochs=EPOCHS, \n","              batch_size=BATCH_SIZE, \n","              validation_data=(x_test, y_test), \n","              shuffle=True,\n","              callbacks=[reduce_lr])\n","    \n","    # Collect results\n","    train_loss = model.history.history[\"loss\"]\n","    valid_loss = model.history.history[\"val_loss\"]\n","    train_acc = model.history.history[\"acc\"]\n","    valid_acc = model.history.history[\"val_acc\"]\n","    \n","    exp_name_tag = \"exp-lr-%s-optimizer-%s-factor-%s-patience-%s\" % (str(lr), str(opti),str(fct),str(pte))\n","    results[exp_name_tag] = {'train-loss': train_loss,\n","                             'valid-loss': valid_loss,\n","                             'train-acc': train_acc,\n","                             'valid-acc': valid_acc}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iw4oy5pgmpPk","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline \n","    \n","NUM_COLORS = len(results.keys())\n","cm = plt.get_cmap('gist_rainbow')\n","color_bar = [cm(1.*i/NUM_COLORS) for i in range(NUM_COLORS)]\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Loss\")\n","plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.show()\n","\n","plt.figure(figsize=(8,6))\n","for i, cond in enumerate(results.keys()):\n","    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n","    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n","plt.title(\"Accuracy\")\n","plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n","plt.show()"],"execution_count":0,"outputs":[]}]}